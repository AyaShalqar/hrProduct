================================================================================
              ПЛАН: ПАРСИНГ 10,000 ПРОФИЛЕЙ LINKEDIN
================================================================================

ВАЖНО: LinkedIn агрессивно банит за массовый сбор данных.
10,000 профилей — это серьёзный объём. Нужна стратегия.

================================================================================
## РАСЧЁТ ВРЕМЕНИ
================================================================================

Безопасный лимит на 1 аккаунт: ~100 профилей/день

С 1 аккаунтом: 10,000 / 100 = 100 дней
С 5 аккаунтами: 10,000 / 500 = 20 дней
С 10 аккаунтами: 10,000 / 1000 = 10 дней

РЕКОМЕНДАЦИЯ: 3-5 аккаунтов, 2-3 недели

================================================================================
## МЕТОД 1: РОТАЦИЯ АККАУНТОВ
================================================================================

Создать несколько LinkedIn аккаунтов (или использовать существующие).
Каждый аккаунт парсит свою порцию, потом отдыхает.

Структура файлов:
```
accounts/
  ├── account1_storage.json
  ├── account2_storage.json
  ├── account3_storage.json
  └── ...
```

Логика:
```python
ACCOUNTS = [
    "account1_storage.json",
    "account2_storage.json",
    "account3_storage.json",
]

# Ротация: каждый аккаунт работает 50-100 профилей, потом переключение
current_account_index = 0
profiles_this_account = 0
MAX_PER_ACCOUNT = 80

def switch_account():
    global current_account_index, profiles_this_account
    current_account_index = (current_account_index + 1) % len(ACCOUNTS)
    profiles_this_account = 0
    # Пауза между аккаунтами 5-10 минут
    time.sleep(random.uniform(300, 600))
```

================================================================================
## МЕТОД 2: РОТАЦИЯ ПРОКСИ (КРИТИЧНО!)
================================================================================

LinkedIn отслеживает IP. Один IP + много запросов = бан.

Варианты прокси:

1. РЕЗИДЕНТНЫЕ ПРОКСИ (рекомендуется)
   - Bright Data, Smartproxy, Oxylabs
   - $10-15 за 1GB трафика
   - Выглядят как обычные пользователи

2. МОБИЛЬНЫЕ ПРОКСИ
   - Дороже, но надёжнее
   - IP меняется при переподключении

3. РОТАЦИЯ ПРОКСИ
   - Новый IP каждые 5-10 минут или каждые N запросов

Реализация:
```python
PROXIES = [
    "http://user:pass@proxy1.example.com:8080",
    "http://user:pass@proxy2.example.com:8080",
    # ... список прокси
]

def get_random_proxy():
    return random.choice(PROXIES)

# При создании браузера:
browser = p.chromium.launch(
    headless=False,
    proxy={"server": get_random_proxy()}
)
```

Ротация прокси + аккаунта:
```python
# Каждые 30-50 профилей менять прокси
if profiles_count % random.randint(30, 50) == 0:
    browser.close()
    browser = p.chromium.launch(proxy={"server": get_random_proxy()})
```

================================================================================
## МЕТОД 3: FINGERPRINT ЗАЩИТА
================================================================================

LinkedIn проверяет "отпечаток" браузера. Нужно его рандомизировать.

1. Использовать playwright-stealth:
```bash
pip install playwright-stealth
```

```python
from playwright_stealth import stealth_sync

browser = p.chromium.launch(headless=False)
page = browser.new_page()
stealth_sync(page)  # Применить stealth
```

2. Рандомизация viewport:
```python
VIEWPORTS = [
    {"width": 1920, "height": 1080},
    {"width": 1366, "height": 768},
    {"width": 1536, "height": 864},
    {"width": 1440, "height": 900},
]

context = browser.new_context(
    viewport=random.choice(VIEWPORTS),
    storage_state=account_file
)
```

3. Рандомизация User-Agent:
```python
USER_AGENTS = [
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15",
]

context = browser.new_context(
    user_agent=random.choice(USER_AGENTS),
    ...
)
```

================================================================================
## МЕТОД 4: УМНЫЕ ЗАДЕРЖКИ
================================================================================

Не просто random(5, 10), а имитация реального поведения:

```python
import numpy as np

def human_delay():
    """Задержка с нормальным распределением (как у человека)"""
    # Среднее 8 сек, стандартное отклонение 3 сек
    delay = np.random.normal(8, 3)
    return max(3, min(delay, 20))  # От 3 до 20 сек

def reading_time():
    """Время 'чтения' страницы"""
    # Иногда человек читает долго
    if random.random() < 0.15:  # 15% шанс
        return random.uniform(20, 45)  # Долгое чтение
    return random.uniform(5, 12)  # Обычное

def break_time():
    """Периодические перерывы"""
    # Каждые 20-40 профилей — перерыв 5-15 минут
    return random.uniform(300, 900)  # 5-15 минут
```

Паттерн работы:
```python
profiles_since_break = 0

for page_num in range(MAX_PAGES):
    collect_profiles(page)

    profiles_since_break += 10  # ~10 профилей на страницу

    # Перерыв каждые 30-50 профилей
    if profiles_since_break >= random.randint(30, 50):
        print(f"Перерыв на {break_time()/60:.1f} минут...")
        time.sleep(break_time())
        profiles_since_break = 0

    time.sleep(human_delay())
```

================================================================================
## МЕТОД 5: РАСПРЕДЕЛЕНИЕ ПО ВРЕМЕНИ
================================================================================

Не парсить 24/7. Имитировать рабочий день:

```python
from datetime import datetime, time as dtime

def is_working_hours():
    """Работать только в 'рабочее' время"""
    now = datetime.now().time()
    # Работа с 9:00 до 22:00
    return dtime(9, 0) <= now <= dtime(22, 0)

def wait_for_working_hours():
    while not is_working_hours():
        print("Ждём рабочего времени...")
        time.sleep(1800)  # Проверять каждые 30 минут
```

Расписание на неделю:
```
Понедельник:  9:00-12:00, 14:00-18:00, 20:00-22:00
Вторник:      10:00-13:00, 15:00-19:00
...
Суббота:      11:00-14:00 (меньше активности)
Воскресенье:  выходной
```

================================================================================
## МЕТОД 6: СЕГМЕНТАЦИЯ ПОИСКА
================================================================================

Вместо одного поиска на 10,000 — разбить на сегменты:

По городам:
  - frontend + Алматы
  - frontend + Астана
  - frontend + Караганда
  - ...

По ключевым словам:
  - frontend developer
  - front-end
  - react developer
  - vue developer
  - ...

Это даёт:
  1. Меньше страниц за один поиск
  2. Легче отслеживать прогресс
  3. Меньше подозрений (разные поиски)

```python
SEARCH_SEGMENTS = [
    {"query": "frontend", "location": "Алматы"},
    {"query": "frontend", "location": "Астана"},
    {"query": "react developer", "location": "Казахстан"},
    {"query": "vue developer", "location": "Казахстан"},
    # ...
]

completed_segments = load_progress()  # Загрузить прогресс

for segment in SEARCH_SEGMENTS:
    if segment in completed_segments:
        continue  # Уже собрано

    collect_segment(segment)
    save_progress(segment)

    # Пауза между сегментами
    time.sleep(random.uniform(600, 1200))  # 10-20 минут
```

================================================================================
## МЕТОД 7: ОБНАРУЖЕНИЕ БАНА
================================================================================

```python
def check_for_ban(page):
    """Проверка на бан/капчу/ограничения"""

    # Капча
    if page.locator("text=security verification").is_visible():
        return "CAPTCHA"

    if page.locator("text=Let's do a quick security check").is_visible():
        return "CAPTCHA"

    # Ограничение поиска
    if page.locator("text=You've reached the search limit").is_visible():
        return "SEARCH_LIMIT"

    # Временный бан
    if "challenge" in page.url:
        return "CHALLENGE"

    if page.locator("text=unusual activity").is_visible():
        return "SUSPICIOUS"

    return None

# Использование:
ban_status = check_for_ban(page)
if ban_status:
    print(f"ОБНАРУЖЕН БАН: {ban_status}")
    save_progress()  # Сохранить прогресс

    if ban_status == "SEARCH_LIMIT":
        # Ждать до следующего дня
        wait_until_tomorrow()
    else:
        # Переключить аккаунт/прокси
        switch_account()
        switch_proxy()
```

================================================================================
## МЕТОД 8: СОХРАНЕНИЕ И ВОССТАНОВЛЕНИЕ
================================================================================

Критично при таком объёме — не потерять данные:

```python
import json
from datetime import datetime

PROGRESS_FILE = "progress.json"
PROFILES_FILE = "profiles.json"

def load_progress():
    try:
        with open(PROGRESS_FILE, "r") as f:
            return json.load(f)
    except FileNotFoundError:
        return {
            "completed_segments": [],
            "current_segment": None,
            "current_page": 1,
            "total_profiles": 0,
            "last_run": None
        }

def save_progress(progress):
    progress["last_run"] = datetime.now().isoformat()
    with open(PROGRESS_FILE, "w") as f:
        json.dump(progress, f, indent=2)

def save_profiles(profiles):
    # Дозапись, не перезапись
    existing = []
    try:
        with open(PROFILES_FILE, "r") as f:
            existing = json.load(f)
    except FileNotFoundError:
        pass

    # Убрать дубликаты
    existing_urls = {p["url"] for p in existing}
    new_profiles = [p for p in profiles if p["url"] not in existing_urls]

    all_profiles = existing + new_profiles
    with open(PROFILES_FILE, "w", encoding="utf-8") as f:
        json.dump(all_profiles, f, ensure_ascii=False, indent=2)

    return len(new_profiles)
```

================================================================================
## ИТОГОВАЯ АРХИТЕКТУРА
================================================================================

```
parserHR/
├── accounts/
│   ├── account1_storage.json
│   ├── account2_storage.json
│   └── account3_storage.json
├── data/
│   ├── profiles.json          # Все собранные профили
│   ├── progress.json          # Прогресс парсинга
│   └── errors.log             # Лог ошибок
├── config.py                  # Настройки (прокси, лимиты)
├── stealth.py                 # Антидетект функции
├── collector.py               # Основная логика сбора
└── main.py                    # Точка входа
```

================================================================================
## РЕКОМЕНДУЕМАЯ СТРАТЕГИЯ ДЛЯ 10,000 ПРОФИЛЕЙ
================================================================================

1. ПОДГОТОВКА (1 день):
   - Создать 3-5 LinkedIn аккаунтов
   - Купить резидентные прокси (5-10 штук)
   - Установить playwright-stealth
   - Настроить структуру проекта

2. ТЕСТИРОВАНИЕ (2-3 дня):
   - Протестировать на 100-200 профилях
   - Настроить задержки
   - Проверить детекцию бана

3. СБОР (2-3 недели):
   - 300-500 профилей в день
   - Ротация аккаунтов каждые 80-100 профилей
   - Ротация прокси каждые 30-50 профилей
   - Перерывы каждые 30-50 профилей
   - Работа только в "рабочие часы"

4. МОНИТОРИНГ:
   - Проверять логи каждый день
   - При бане — пауза 24-48 часов для аккаунта
   - Регулярно бэкапить данные

================================================================================
## БЮДЖЕТ
================================================================================

Минимальный:
  - 3 LinkedIn аккаунта: бесплатно (но риск бана)
  - 5 резидентных прокси: ~$20-30

Рекомендуемый:
  - 5 LinkedIn аккаунтов
  - 10 резидентных прокси: ~$40-50
  - Сервис антидетект (опционально): $20-50/мес

================================================================================
## АЛЬТЕРНАТИВА: LINKEDIN API / SALES NAVIGATOR
================================================================================

Если есть бюджет — рассмотреть официальные методы:

1. LinkedIn Sales Navigator ($99/мес)
   - Легальный доступ к расширенному поиску
   - До 2,500 результатов поиска
   - Можно экспортировать в CRM

2. LinkedIn Recruiter ($170/мес)
   - Ещё больше возможностей
   - Bulk actions

3. Сторонние сервисы:
   - PhantomBuster, Dux-Soup, LinkedHelper
   - Уже решили проблемы антибота
   - $50-100/мес

Для 10,000 профилей может быть выгоднее использовать готовое решение.

================================================================================
